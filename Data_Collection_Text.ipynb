{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of museum-related tweets in New York City\n",
    "## Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Tweepy package, collecting data from Twitter API within a specified radius from museum locations and park (control sample) locations in New York City"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "\n",
    "import tweepy\n",
    "from tweepy.auth import OAuthHandler\n",
    "import json \n",
    "import pandas\n",
    "import nltk\n",
    "\n",
    "# Accessing Twitter API using information in a created Twitter Apps https://apps.twitter.com/\n",
    "\n",
    "consumer_key = '3NDy4jVYRoBbmPgPSGEBnmsfV' \n",
    "consumer_secret = 'PAMlN4ytRkpJJi8A2g51jz4gt6rUoIpaYc5TbGqoi26Mi4MmXw' \n",
    "access_token = '804067294485872640-7k6Hra6LTrZu2NXmWLwt3tcflHLufdz' \n",
    "access_secret = 'WhKatXNODv2uyitX8FEkOGxuLJAJgAsicCrt2Ix8LNWmh' \n",
    "auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "auth.set_access_token(access_token, access_secret) \n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser()) # Using JSON Parser to read the Twitter formatting\n",
    "\n",
    "# Reference link: http://www.tweepy.org/\n",
    "# Reference link: https://stackoverflow.com/questions/27900451/convert-tweepy-status-object-into-json#comment44408594_27901076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Near-museum data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading in a .csv file with the locations of museums in New York City in a latitude-longitude format\n",
    "\n",
    "list_of_museums = pandas.read_csv('Museum_location_file.csv', encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Saving lat-long data from a column in a file\n",
    "\n",
    "list_museums = list_of_museums['lat_long'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data within 100 meter radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_for_df_status = [] # Creating empty lists for status and date data \n",
    "list_for_df_date = [] \n",
    "for parameter in list_museums: # Iterating through a list of 130 museums \n",
    "    tweets = api.search(geocode=parameter + ',' + '0.1km') # Specifying a lat-long as parameter and buffer radius\n",
    "    text = json.dumps(tweets) # Loading tweet content \n",
    "    json_file = json.loads(text) \n",
    "    for i in json_file['statuses']: # Extracting status and date of tweets \n",
    "        status = i['text'] \n",
    "        date = i['created_at'] \n",
    "        list_for_df_status.append(status) \n",
    "        list_for_df_date.append(date) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe with status text and date and returning a .csv file\n",
    "\n",
    "data = pandas.DataFrame(list_for_df_status, columns=['status'])\n",
    "data['date']=list_for_df_date\n",
    "data.to_csv('Tweets_museum_100.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data within 250 meter radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_for_df_status = [] # Creating empty lists for status and date data \n",
    "list_for_df_date = [] \n",
    "for parameter in list_museums: # Iterating through a list of 130 museums \n",
    "    tweets = api.search(geocode=parameter + ',' + '0.25km') # Specifying a lat-long as parameter and buffer radius\n",
    "    text = json.dumps(tweets) # Loading tweet content \n",
    "    json_file = json.loads(text) \n",
    "    for i in json_file['statuses']: # Extracting status and date of tweets \n",
    "        status = i['text'] \n",
    "        date = i['created_at'] \n",
    "        list_for_df_status.append(status) \n",
    "        list_for_df_date.append(date) \n",
    "        \n",
    "# Creating a dataframe with status text and date and returning a .csv file\n",
    "\n",
    "data = pandas.DataFrame(list_for_df_status, columns=['status'])\n",
    "data['date']=list_for_df_date\n",
    "data.to_csv('Tweets_museum_200.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data within 500 meter radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_for_df_status = [] # Creating empty lists for status and date data \n",
    "list_for_df_date = [] \n",
    "for parameter in list_museums: # Iterating through a list of 130 museums \n",
    "    tweets = api.search(geocode=parameter + ',' + '0.5km') # Specifying a lat-long as parameter and buffer radius\n",
    "    text = json.dumps(tweets) # Loading tweet content \n",
    "    json_file = json.loads(text) \n",
    "    for i in json_file['statuses']: # Extracting status and date of tweets \n",
    "        status = i['text'] \n",
    "        date = i['created_at'] \n",
    "        list_for_df_status.append(status) \n",
    "        list_for_df_date.append(date) \n",
    "        \n",
    "# Creating a dataframe with status text and date and returning a .csv file\n",
    "\n",
    "data = pandas.DataFrame(list_for_df_status, columns=['status'])\n",
    "data['date']=list_for_df_date\n",
    "data.to_csv('Tweets_museum_500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data within 1 km radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_for_df_status = [] # Creating empty lists for status and date data \n",
    "list_for_df_date = [] \n",
    "for parameter in list_museums: # Iterating through a list of 130 museums \n",
    "    tweets = api.search(geocode=parameter + ',' + '1km') # Specifying a lat-long as parameter and buffer radius\n",
    "    text = json.dumps(tweets) # Loading tweet content \n",
    "    json_file = json.loads(text) \n",
    "    for i in json_file['statuses']: # Extracting status and date of tweets \n",
    "        status = i['text'] \n",
    "        date = i['created_at'] \n",
    "        list_for_df_status.append(status) \n",
    "        list_for_df_date.append(date) \n",
    "        \n",
    "# Creating a dataframe with status text and date and returning a .csv file\n",
    "\n",
    "data = pandas.DataFrame(list_for_df_status, columns=['status'])\n",
    "data['date']=list_for_df_date\n",
    "data.to_csv('Tweets_museum_1km.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Near-park data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reading in a .csv file with the locations of parks in New York City in a latitude-longitude format\n",
    "\n",
    "list_of_points = pandas.read_csv('Park_location_file.csv')\n",
    "list_points = list_of_points['lat_long'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data within 100 meter radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_for_df_status = [] # Creating empty lists for status and date data \n",
    "list_for_df_date = [] \n",
    "for parameter in list_points: # Iterating through a list of 131 parks\n",
    "    tweets = api.search(geocode=parameter + ',' + '0.1km') # Specifying a lat-long as parameter and buffer radius\n",
    "    text = json.dumps(tweets) # Loading tweet content \n",
    "    json_file = json.loads(text) \n",
    "    for i in json_file['statuses']: # Extracting status and date of tweets \n",
    "        status = i['text'] \n",
    "        date = i['created_at'] \n",
    "        list_for_df_status.append(status) \n",
    "        list_for_df_date.append(date) \n",
    "        \n",
    "# Creating a dataframe with status text and date and returning a .csv file\n",
    "\n",
    "data = pandas.DataFrame(list_for_df_status, columns=['status'])\n",
    "data['date']=list_for_df_date\n",
    "data.to_csv('Park_tweets_100m.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Downloading data within 250 meter radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_for_df_status = [] # Creating empty lists for status and date data \n",
    "list_for_df_date = [] \n",
    "for parameter in list_points: # Iterating through a list of 131 parks\n",
    "    tweets = api.search(geocode=parameter + ',' + '0.25km') # Specifying a lat-long as parameter and buffer radius\n",
    "    text = json.dumps(tweets) # Loading tweet content \n",
    "    json_file = json.loads(text) \n",
    "    for i in json_file['statuses']: # Extracting status and date of tweets \n",
    "        status = i['text'] \n",
    "        date = i['created_at'] \n",
    "        list_for_df_status.append(status) \n",
    "        list_for_df_date.append(date) \n",
    "        \n",
    "# Creating a dataframe with status text and date and returning a .csv file\n",
    "\n",
    "data = pandas.DataFrame(list_for_df_status, columns=['status'])\n",
    "data['date']=list_for_df_date\n",
    "data.to_csv('Park_tweets_250m.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data within 500 meter radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_for_df_status = [] # Creating empty lists for status and date data \n",
    "list_for_df_date = [] \n",
    "for parameter in list_points: # Iterating through a list of 131 parks\n",
    "    tweets = api.search(geocode=parameter + ',' + '0.5km') # Specifying a lat-long as parameter and buffer radius\n",
    "    text = json.dumps(tweets) # Loading tweet content \n",
    "    json_file = json.loads(text) \n",
    "    for i in json_file['statuses']: # Extracting status and date of tweets \n",
    "        status = i['text'] \n",
    "        date = i['created_at'] \n",
    "        list_for_df_status.append(status) \n",
    "        list_for_df_date.append(date) \n",
    "        \n",
    "# Creating a dataframe with status text and date and returning a .csv file\n",
    "\n",
    "data = pandas.DataFrame(list_for_df_status, columns=['status'])\n",
    "data['date']=list_for_df_date\n",
    "data.to_csv('Park_tweets_500m.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading data within 1 km radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_for_df_status = [] # Creating empty lists for status and date data \n",
    "list_for_df_date = [] \n",
    "for parameter in list_points: # Iterating through a list of 131 parks\n",
    "    tweets = api.search(geocode=parameter + ',' + '1km') # Specifying a lat-long as parameter and buffer radius\n",
    "    text = json.dumps(tweets) # Loading tweet content \n",
    "    json_file = json.loads(text) \n",
    "    for i in json_file['statuses']: # Extracting status and date of tweets \n",
    "        status = i['text'] \n",
    "        date = i['created_at'] \n",
    "        list_for_df_status.append(status) \n",
    "        list_for_df_date.append(date) \n",
    "        \n",
    "# Creating a dataframe with status text and date and returning a .csv file\n",
    "\n",
    "data = pandas.DataFrame(list_for_df_status, columns=['status'])\n",
    "data['date']=list_for_df_date\n",
    "data.to_csv('Park_tweets_1km.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
